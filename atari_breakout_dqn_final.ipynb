{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "K1tO1co8QqoG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "K1tO1co8QqoG",
    "outputId": "44c5d9d1-811c-437e-c777-6bdb65af4717"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport os\\nif(os.getcwd() != '/content'):\\n  os.chdir('/content')\\n\\nos.getcwd()\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "if(os.getcwd() != '/content'):\n",
    "  os.chdir('/content')\n",
    "\n",
    "os.getcwd()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "gWc-3SWGG3Rk",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWc-3SWGG3Rk",
    "outputId": "5a01687d-2a8e-43a6-9cf2-70cebca57721"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom google.colab import drive\\ndrive.mount(\"/content/drive\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "Xn6epHwKAXNd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xn6epHwKAXNd",
    "outputId": "91c7e21f-75f8-4df8-9e97-ef5aca06f496"
   },
   "outputs": [],
   "source": [
    "#!git clone https://github.com/openai/baselines.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "KDwlDLAEDIXR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDwlDLAEDIXR",
    "outputId": "c4abda1c-6fb6-40e5-f633-d1c97d3fe245"
   },
   "outputs": [],
   "source": [
    "#!pip install gym[atari]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aZYHW7PmHvqg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aZYHW7PmHvqg",
    "outputId": "ea9fa117-4334-486a-d782-515c6fc1a259"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install atari-py\\n!apt-get install -y wget\\n\\n# Download the Atari ROMs\\n!wget -P /content/ http://www.atarimania.com/roms/Atari-2600-VCS-ROM-Collection.zip\\n# Unzip the ROMs\\n!unzip -o Atari-2600-VCS-ROM-Collection.zip\\n\\n# Remove the downloaded zip file\\n!rm /content/Atari-2600-VCS-ROM-Collection.zip\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "!pip install atari-py\n",
    "!apt-get install -y wget\n",
    "\n",
    "# Download the Atari ROMs\n",
    "!wget -P /content/ http://www.atarimania.com/roms/Atari-2600-VCS-ROM-Collection.zip\n",
    "# Unzip the ROMs\n",
    "!unzip -o Atari-2600-VCS-ROM-Collection.zip\n",
    "\n",
    "# Remove the downloaded zip file\n",
    "!rm /content/Atari-2600-VCS-ROM-Collection.zip\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8FZzD9vzAoZN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8FZzD9vzAoZN",
    "outputId": "31812ec0-0a03-4b99-a1da-3727fac3b187"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport os\\n\\n# Change to the baselines directory\\nos.chdir('baselines')\\n\\n# Install the baselines package\\n!pip install -e .\\nos.chdir('..')\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "\n",
    "# Change to the baselines directory\n",
    "os.chdir('baselines')\n",
    "\n",
    "# Install the baselines package\n",
    "!pip install -e .\n",
    "os.chdir('..')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gmJDsjdLKZYE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gmJDsjdLKZYE",
    "outputId": "17ca2df1-a7af-475d-8cba-0bace8fe71ed"
   },
   "outputs": [],
   "source": [
    "#!python -m atari_py.import_roms \"/content/ROMS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "q_tZetqqUTKb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_tZetqqUTKb",
    "outputId": "886196bc-37ae-41bc-f9fd-6fb2f9d48c3d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nif type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\\n    !bash ../xvfb start\\n    %env DISPLAY=:1\\n    '"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\"))==0:\n",
    "    !bash ../xvfb start\n",
    "    %env DISPLAY=:1\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "flHyZfr-HkLF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "flHyZfr-HkLF",
    "outputId": "59d71955-a868-485f-ba96-b55c95d19f26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport os\\nif not os.path.exists('drive/MyDrive/dqn_breakout/v2'):\\n    os.makedirs('drive/MyDrive/dqn_breakout/v2')\\n\\nos.chdir('drive/MyDrive/dqn_breakout')\\nos.getcwd()\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "import os\n",
    "if not os.path.exists('drive/MyDrive/dqn_breakout/v2'):\n",
    "    os.makedirs('drive/MyDrive/dqn_breakout/v2')\n",
    "\n",
    "os.chdir('drive/MyDrive/dqn_breakout')\n",
    "os.getcwd()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3121d7d-3095-4cd6-9efe-c1896376fc0d",
   "metadata": {
    "id": "d3121d7d-3095-4cd6-9efe-c1896376fc0d"
   },
   "outputs": [],
   "source": [
    "from baselines.common.atari_wrappers import make_atari, wrap_deepmind\n",
    "import gym\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import math\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import copy\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f10f6163-17eb-4957-9a7d-0a98bc4ea455",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f10f6163-17eb-4957-9a7d-0a98bc4ea455",
    "outputId": "e98f4e8f-20e8-448f-cc5a-1c45267480c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f352e185-05da-4c4e-9474-7f2ad814ec9e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f352e185-05da-4c4e-9474-7f2ad814ec9e",
    "outputId": "081eaed0-127b-45d2-b760-8db9e41f3683"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15.7\n"
     ]
    }
   ],
   "source": [
    "print(gym.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72683b60-ebb4-40d7-98d4-9992eac7a220",
   "metadata": {
    "id": "72683b60-ebb4-40d7-98d4-9992eac7a220"
   },
   "source": [
    "# CONCETTI PRINCIPALI DQN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c1241e-ba47-444d-9150-882afe007b37",
   "metadata": {
    "id": "40c1241e-ba47-444d-9150-882afe007b37"
   },
   "source": [
    "![POLICY_NETWORK](images/policy_network.png)<br>\n",
    "Dopo aver memorizzato un'esperienza nella replay memory, si procede a campionare una batch casuale di esperienze dalla replay memory.\n",
    "A partire da un singolo campione (generalizzando a una batch) di esperienza dalla memoria, si procede a una preelaborazione dello stato (conversione in scala di grigi, ritaglio, scalatura, ecc.) e si passa lo stato preelaborato alla rete come input. L'obiettivo della rete è quello di approssimare la policy ottimale trovando la Q-function ottimale.\n",
    "\n",
    "I dati dello stato di input vengono propogati nella rete e vengono calcolati i Q-values per ciascuna azione in quello stato.\n",
    "\n",
    "Si calcola quindi la loss. Per farlo, si confronta il valore Q emesso dalla rete per l'azione nella tupla di esperienza che abbiamo campionato e il corrispondente valore Q ottimale, o valore Q target, per la stessa azione.\n",
    "\n",
    "Il valore Q target viene calcolato utilizzando l'espressione del lato destro dell'equazione di Bellman. Quindi la loss viene calcolata sottraendo il valore Q per una data coppia stato-azione dal valore Q ottimale per la stessa coppia stato-azione.\n",
    "\n",
    "![TARGET_NETWORK](images/target_network.png)<br>\n",
    "Per calcolare il target Q-value viene fatto un altro forward pass prendendo lo stato s' (next state) dalla tupla dell'esperienza campionata. Viene utilizzata una seconda rete (TARGET NETWORK), una copia della policy network (copia dei pesi dalla policy network periodicamente). Viene preso il Q-value massimo tra le possibili azioni.\n",
    "\n",
    "Questo secondo forward pass serve quindi per aiutarci a calcolare la loss.\n",
    "\n",
    "La discesa del gradiente viene quindi eseguita per aggiornare i pesi della rete nel tentativo di minimizzare la perdita. In questo caso, minimizzare la perdita significa puntare a far sì che la rete produca valori Q per ogni coppia stato-azione che si avvicinino ai valori Q target dati dall'equazione di Bellman.\n",
    "\n",
    "Fino a questo punto, tutto ciò che abbiamo esaminato riguardava un singolo passo temporale. Passiamo quindi alla fase temporale successiva dell'episodio e ripetiamo questo processo più volte, finché non raggiungiamo la fine dell'episodio. A quel punto, iniziamo un nuovo episodio e continuiamo a farlo finché non raggiungiamo il numero massimo di episodi stabilito. Continueremo a ripetere questo processo fino a quando non avremo minimizzato a sufficienza la perdita.\n",
    "\n",
    "RECAP\n",
    "\n",
    "![algorithm](images/algorithm.png)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef1d827-5e12-4a09-bff3-ac3e3aa73a0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8ef1d827-5e12-4a09-bff3-ac3e3aa73a0f",
    "outputId": "4c4ac05a-dd70-45da-c971-5a56cb547c8f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "091b63e3-2900-4d8f-b0fe-cc80708950bd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "091b63e3-2900-4d8f-b0fe-cc80708950bd",
    "outputId": "dcd1f52a-f64f-4225-eef2-1d064619ff3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "#tf.debugging.set_log_device_placement(True)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b678b6e4-c334-45a0-8aad-45be84d4653c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b678b6e4-c334-45a0-8aad-45be84d4653c",
    "outputId": "05dff110-4269-47ad-876e-082a9661a71f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Livio\\anaconda3\\envs\\dqn-breakout\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<baselines.common.atari_wrappers.LazyFrames at 0x23aa6ad5f00>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 42\n",
    "# Use the Baseline Atari environment because of Deepmind helper functions\n",
    "env = make_atari(\"BreakoutNoFrameskip-v4\")\n",
    "# Warp the frames, grey scale, stake four frame and scale to smaller ratio\n",
    "env = wrap_deepmind(env, frame_stack=True, scale=True)\n",
    "env.seed(seed)\n",
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d57312c-b4a1-4def-ab3c-7440e7216cda",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d57312c-b4a1-4def-ab3c-7440e7216cda",
    "outputId": "93a8b1c4-9668-4a15-ee55-1d1c873b8658"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 84, 4)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dim = env.observation_space.shape\n",
    "state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "018add44-e4a4-442b-aaa4-3d6e8c10d949",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "018add44-e4a4-442b-aaa4-3d6e8c10d949",
    "outputId": "4aa01491-ffee-4b06-8735-dab19b506695"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions = env.action_space.n\n",
    "n_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "250a614c-922c-496d-8ecc-261747ddb26c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "250a614c-922c-496d-8ecc-261747ddb26c",
    "outputId": "de65609f-1381-493d-d73b-461e572e9b17"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVEAAAGxCAYAAADbMoXAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsX0lEQVR4nO3de1AUZ74+8KcZhgERRhBhZhSRuJpV8ZCAxttGLklQvG1iTrwku9GzllnPRmsttZIQK5FsZcWTLU0s3VzOxvWSoFhJ1DXqiWIUjHFzjveA8ZdFgwHNjEQjDCAMl3l/f+xJn4wMl+GdZhh5PlVv6fT7Tve3W3js7unpVoQQAkRE1CkBvi6AiMifMUSJiCQwRImIJDBEiYgkMESJiCQwRImIJDBEiYgkMESJiCQwRImIJDBEqV1ffvklFixYgMGDByMkJAQhISEYMmQIfvvb3+LUqVO+Lq9TsrOzoSiKr8ugu4DCr31SW9555x0sXrwY9957L5555hmMGDECiqLg4sWL2LFjBz7//HNcunQJgwcP9nWpHrl69SquXr2KsWPH+roU8nMMUWrV559/jokTJ2Lq1Kn48MMPERQU1GLMBx98gAkTJsBisfigQiLf4+E8tWr16tXQ6XR455133AYoADzxxBMuAXrq1CnMmTMHgwYNQkhICAYNGoS5c+fi22+/dXnfli1boCgKjhw5goULF6Jv374IDw/H008/jdraWthsNsyaNQt9+vSB2WzGihUr0NjY6DKPhoYGvPrqq/j5z38Og8GAfv364d/+7d/w/ffft7tu7g7nBw0ahGnTpmHfvn24//77ERISgmHDhmHfvn1qzcOGDUNoaCgeeOCBFqcyOrruAHD8+HGMGzcOwcHB6N+/P1566SW8++67UBQFV65ccRm7c+dOjBs3DqGhoejduzcmTZqEs2fPtruO1EUEkRtNTU0iJCREjBs3zqP3ffDBB+Lll18Wu3fvFoWFhSIvL0+kpKSIfv36ie+//14dt3nzZgFAxMfHi+XLl4tDhw6J//iP/xA6nU7MnTtXJCUliVdffVXk5+eL559/XgAQa9euVd/f3NwsJk+eLEJDQ8Urr7wi8vPzxbvvviv69+8vhg8fLm7fvt1mnatWrRJ3/vjHxcWJAQMGiISEBLFjxw5x4MABMWbMGKHX68XLL78sJkyYIHbt2iV2794thg4dKmJiYlyW09F1P3/+vAgODhb/8i//IvLy8sTevXvFlClTxKBBgwQAUVpaqo794x//KBRFEb/5zW/Evn37xK5du8S4ceNEaGiouHDhgkf/NqQNhii5ZbPZBAAxZ86cFn1NTU2isbFRbU6ns9X5NDU1iZqaGhEaGirWr1+vTv8xRJcsWeIy/tFHHxUAxLp161ym33fffSIpKUl9vWPHDgFAfPTRRy7jTp48KQCIN998s831ay1EQ0JCxNWrV9Vp586dEwCE2WwWtbW16vQ9e/YIAGLv3r0er/sTTzwhQkNDXYK1ublZDB8+3CVEy8rKRGBgYIttVF1dLUwmk5g1a1ab60hdg4fz5LHk5GTo9Xq1rV27Vu2rqanB888/j5/97GcIDAxEYGAgevfujdraWly8eLHFvKZNm+byetiwYQCAqVOntpj+08Piffv2oU+fPpg+fTqamprUdt9998FkMqGgoKBT63bfffehf//+LepJTU1Fr169Wkz/aU0dXffCwkKkp6cjKipKnRYQEIBZs2a51HLw4EE0NTXh6aefdlnH4OBgpKSkdHodybsCfV0AdU9RUVEICQlxez5v+/btuH37NqxWK2bMmOHS9+STT+LTTz/FSy+9hNGjRyM8PByKomDKlCmoq6trMa/IyEiX1z+ee3U3vb6+Xn19/fp1VFZWtnqu9saNGx1bUYl6ALjU1NF1v3nzJmJiYlos+85p169fBwCMHj3aba0BAdwH6g4YouSWTqdDeno6Dh06BKvVCrPZrPYNHz4cAFp8AFJVVYV9+/Zh1apVeOGFF9TpDocDP/zwg1fri4qKQt++ffHJJ5+47Q8LC/Pq8trjybr37dtXDcifstlsLq9/3FP98MMPERcXp0HV5A0MUWpVVlYW/uu//guLFi3Chx9+CL1e3+Z4RVEghIDBYHCZ/u6776K5udmrtU2bNg15eXlobm7GmDFjvDrvzvBk3VNSUnDgwAHcuHFDDUqn04kPPvjAZdykSZMQGBiIy5cv4/HHH9d2BajTGKLUqgkTJuDPf/4zlixZgqSkJPVi+4CAAFitVnz00UcAgPDwcPXPiRMn4k9/+hOioqIwaNAgFBYWYtOmTejTp49Xa5szZw5yc3MxZcoU/P73v8cDDzwAvV6Pq1ev4ujRo/jlL3+Jxx57zKvLbIsn675y5Up8/PHHeOihh7By5UqEhITg7bffRm1tLYD/O0wfNGgQ/vCHP2DlypX45ptvMHnyZEREROD69ev4n//5H4SGhuKVV17psnUk9xii1KZFixZh3LhxWL9+PV5//XV89913UBQFAwYMwPjx4/Hpp58iPT1dHb99+3b8/ve/x3PPPYempiZMmDAB+fn5LT4okqXT6bB3716sX78e7733HnJychAYGIgBAwYgJSUFI0eO9OryOqKj656YmIj8/HysWLECTz/9NCIiIvDrX/8aKSkpeP7552E0GtWxWVlZGD58ONavX48dO3bA4XDAZDJh9OjRWLRoUVevIrnBbywRdRMZGRm4cuUK/vGPf/i6FPIA90SJfGDZsmW4//77ERsbix9++AG5ubnIz8/Hpk2bfF0aeYghSuQDzc3NePnll2Gz2aAoCoYPH4733nsPv/rVr3xdGnmIh/NERBJ4tS4RkQSfhuibb76J+Ph4BAcHIzk5GZ999pkvyyEi8pjPQnTnzp1YunQpVq5cibNnz+LBBx9EZmYmysrKfFUSEZHHfHZOdMyYMUhKSsJbb72lThs2bBgeffRR5OTktPlep9OJ7777DmFhYXzEAxFpQgiB6upqWCyWNu9T4JNP5xsaGnD69GmX7xgD/7xO7sSJEy3GOxwOOBwO9fW1a9fU728TEWmpvLwcAwYMaLXfJ4fzN27cQHNzc4u71sTExLS4CQMA5OTkwGg0qo0BSkRdpb2b2fj0g6U7D8WFEG4Pz7OyslBVVaW28vLyriqRiHq49k4Z+uRwPioqCjqdrsVeZ0VFhdv7LBoMhhZ3xyEi6g58sicaFBSE5ORk5Ofnu0zPz8/H+PHjfVESEVGn+Oxrn8uWLcOvf/1rjBo1CuPGjcN//ud/oqysjHemISK/4rMQnT17Nm7evIk//OEPsFqtSEhIwIEDB3gHbyLyK3753Xm73e5yz8WeJjIy0us3Oa6qqsLNmzfd9vXu3RvR0dFeXV5dXR2sVqvbPoPBAIvF4tVrgJuamnDt2jWv32G/s0wmk8uD77zh+++/R3V1tVfnqYXQ0FC3n30AwO3bt91eoeNLVVVV6o3H3eFdnPzQuHHjkJKS4tV5njhxAnv27HHbd++992L27NleXd7ly5dbfWxIdHQ0FixY0OpD6DqjsrISGzduhN1u99o8OysgIABTp07Fvffe69X5fvTRR/jv//5vr85TC/fccw9+9atfuf1P8uLFi9iyZQv8ad+OIeqHAgICEBjo3X+6tr6RoSgKdDqdV/cM21vej48c9hZv1y9Lp9N16b9hd/Ljz6+7fw+dTueDiuQwRO8y7f0P7u0g6W7L02KZWhBCdHpvyx/WrydhiN5lvvzyS3z55Zdu+0aMGIGkpCSvLq+srAzHjh1z29e/f3+kpqZ6dQ+psrIShw4dQkNDQ4u+8PBwTJo0CcHBwV5bnhacTieOHDmCU6dOefzeCRMm4J577tGgKuoshuhdxmq14uzZs277+vTp4/UQvXXrVqvLq6+vR2pqqleXV1dXh/Pnz6O+vr5FX1RUFB566CGvLk8rly9f7tT7hg0bxhDtZvzjJAoRUTfFPVGibqZv376tXv4UGhraxdVQexiiRN1MZmYmRowY4bbP25/okzz+ixB1M4GBgbzhjh9hiBJ1Q61d/sTLm7ofhihRN/P555/j4sWLbvvGjBmDQYMGdW1B1CaGKFE3U1JS0mrf4MGDGaLdDC9xIiKSwD3Ru0zv3r1hMpnc9rX3rJjOCAkJgdlsdnsOLyIiwuvL0+v1iImJcXlw4U+X5y/fH4+IiOjUh0chISEaVEMyGKJ3mTFjxiA5OdltnxaXx/zsZz/D4sWL3fYFBAR4/YOQvn374plnnnHbpyiKX3yqHRAQgBkzZmDo0KEev1ev12tQEclgiN5l9Hp9l/6i6XS6Lt07CggIuCv2xgwGw12xHsRzokREUrgn6oeKi4tRWVnp1Xl+9913rfaVlZW1esPmzqqsrITT6XTbd+vWLXz88cdePb/pcDhQV1fntfnJcDqdOHHiRKuXMXVWaWmpV+enlWvXrrX68/TDDz/41Q2ZAT4ehIioTe09HoSH80REEvz6cD4yMtJvLmkhIv/idDrxww8/tDvOr0N00aJF3f4u5kTkn+rr67F69ep2x/l1iPbu3ZshSkSa6Oh11TwWJiKSwBAlIpLAECUiksAQJSKSwBAlIpLAECUiksAQJSKSwBAlIpLAECUiksAQJSKS4PUQzcnJwejRoxEWFobo6Gg8+uij+Prrr13GzJ8/H4qiuLSxY8d6uxQiIs15PUQLCwvx7LPP4osvvkB+fj6ampqQkZGB2tpal3GTJ0+G1WpV24EDB7xdChGR5rx+A5JPPvnE5fXmzZsRHR2N06dPY+LEiep0g8HQ6lMpiYj8hebnRKuqqgD8896fP1VQUIDo6GgMHToUCxcuREVFRavzcDgcsNvtLo2IqDvQNESFEFi2bBl+8YtfICEhQZ2emZmJ3NxcHDlyBGvXrsXJkyeRnp7u9lniwD/PsxqNRrXFxsZqWTYRUYdp+oylZ599Fvv378fx48cxYMCAVsdZrVbExcUhLy8PM2fObNHvcDhcAtZutyM2NharV6/m/USJSBP19fV48cUX233GkmY3ZV6yZAn27t2LY8eOtRmgAGA2mxEXF4eSkhK3/QaDAQaDQYsyiYikeD1EhRBYsmQJdu/ejYKCAsTHx7f7nps3b6K8vBxms9nb5RARacrr50SfffZZvP/++9i+fTvCwsJgs9lgs9nUZ37X1NRgxYoV+Pvf/44rV66goKAA06dPR1RUFB577DFvl0NEpCmv74m+9dZbAIDU1FSX6Zs3b8b8+fOh0+lQVFSEbdu2obKyEmazGWlpadi5cyfCwsK8XQ4RkaY0OZxvS0hICA4ePOjtxRIR+QS/O09EJIEhSkQkwa+fO98ZGl4WS0TdlKIoms27R4VoQ0MDjhw5on4VlYjufkajEenp6QgKCtJk/j0qRJuamnD+/Hlcv37d16UQURcxm81ISUnRbP48J0pEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJMHrIZqdnQ1FUVyayWRS+4UQyM7OhsViQUhICFJTU3HhwgVvl0FE1CU02RMdMWIErFar2oqKitS+1157DevWrcPGjRtx8uRJmEwmPPLII6iurtaiFCIiTWkSooGBgTCZTGrr168fgH/uhb7xxhtYuXIlZs6ciYSEBGzduhW3b9/G9u3btSiFiEhTmoRoSUkJLBYL4uPjMWfOHHzzzTcAgNLSUthsNmRkZKhjDQYDUlJScOLEiVbn53A4YLfbXRoRUXfg9RAdM2YMtm3bhoMHD+Ivf/kLbDYbxo8fj5s3b8JmswEAYmJiXN4TExOj9rmTk5MDo9GottjYWG+XTUTUKV4P0czMTDz++OMYOXIkHn74Yezfvx8AsHXrVnWMoigu7xFCtJj2U1lZWaiqqlJbeXm5t8smIuoUzS9xCg0NxciRI1FSUqJ+Sn/nXmdFRUWLvdOfMhgMCA8Pd2lERN2B5iHqcDhw8eJFmM1mxMfHw2QyIT8/X+1vaGhAYWEhxo8fr3UpREReF+jtGa5YsQLTp0/HwIEDUVFRgVdffRV2ux3z5s2DoihYunQpVq9ejSFDhmDIkCFYvXo1evXqhSeffNLbpRARac7rIXr16lXMnTsXN27cQL9+/TB27Fh88cUXiIuLAwA899xzqKurw+9+9zvcunULY8aMwaFDhxAWFubtUoiINOf1EM3Ly2uzX1EUZGdnIzs729uLJiLqcvzuPBGRBIYoEZEEhigRkQSvnxPtzoJ1Osy75x40RkT4uhQi6iL6yEgYdDrN5t+jQlQfEIDJFgt6GY2+LoWIukht794oVhQ0azR/Hs4TEUlgiBIRSWCIEhFJYIgSEUlgiBIRSWCIEhFJYIgSEUlgiBIRSehRF9sDAAIFRKDT11UQUVfRCaD1pw9J61khGiDgjKmDaKj1dSVE1EVEUCBD1Kt0AggUvq6CiLqKxkeePCdKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJKFnXWyvAA59ExSl0deVEFEXceibIRTtvmDTo0JUQKDe0AgRyBAl6ikcOm1/33k4T0QkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkweshOmjQICiK0qI9++yzAID58+e36Bs7dqy3yyAi6hJev9j+5MmTaG5uVl8XFxfjkUcewRNPPKFOmzx5MjZv3qy+DgoK8nYZrRIKNP32AhF1L0Lj422vh2i/fv1cXq9ZswaDBw9GSkqKOs1gMMBkMnl70e0SAUCtpQmOgKYuXzYR+UZTcxNEnXbz1/Rrnw0NDXj//fexbNkyKMr/PW6voKAA0dHR6NOnD1JSUvDHP/4R0dHRrc7H4XDA4XCor+12e+cKUoDmIAGFD6oj6jGamwRQD0CjX3tNd3T37NmDyspKzJ8/X52WmZmJ3NxcHDlyBGvXrsXJkyeRnp7uEpJ3ysnJgdFoVFtsbKyWZRMRdZgihNBst2zSpEkICgrCxx9/3OoYq9WKuLg45OXlYebMmW7HuNsTjY2NxerVqxEcHNzhehTFAaPxYwQGVnb4PUTk35qaIlBVNR1CePbZS319PV588UVUVVUhPDy81XGaHc5/++23OHz4MHbt2tXmOLPZjLi4OJSUlLQ6xmAwwGAweLtEIiJpmh3Ob968GdHR0Zg6dWqb427evIny8nKYzWatSiEi0owmIep0OrF582bMmzcPgYH/t7NbU1ODFStW4O9//zuuXLmCgoICTJ8+HVFRUXjssce0KIWISFOaHM4fPnwYZWVl+M1vfuMyXafToaioCNu2bUNlZSXMZjPS0tKwc+dOhIWFaVEKEZGmNAnRjIwMuPu8KiQkBAcPHtRikUREPsHvzhMRSehRz1hyQoENwRAixNelEFEXUUQwDACUdkd2To8K0SYoOOOMQE2A3telEFEX6S3CMBoKtPqt71EhCvz4zS+t/k8iop6G50SJiCQwRImIJDBEiYgkMESJiCQwRImIJDBEiYgkMESJiCT0uOtEAQVC8DpRop5D29/3nhWiTUFoPpOJJofO15UQURdpNjQD8XZAp81DPHpWiDoD4LweD1Hby9eVEFEXcfauBeKKAV1z+4M7gedEiYgkMESJiCQwRImIJDBEiYgkMESJiCQwRImIJDBEiYgkMESJiCT0qIvthXCituYy7HZ+Y4mopwhAM4TQ5kJ7oIeFaFPTbVwsegO269d9XQoRdRGzyYS0B58BEKzJ/HtUiAICzc31cDbX+7oQIuoiTqcDPz6iUgs8J0pEJIEhSkQkgSFKRCSBIUpEJIEhSkQkgSFKRCSBIUpEJIEhSkQkweMQPXbsGKZPnw6LxQJFUbBnzx6XfiEEsrOzYbFYEBISgtTUVFy4cMFljMPhwJIlSxAVFYXQ0FDMmDEDV69elVoRIiJf8DhEa2trkZiYiI0bN7rtf+2117Bu3Tps3LgRJ0+ehMlkwiOPPILq6mp1zNKlS7F7927k5eXh+PHjqKmpwbRp09DcrN33W4mItODx1z4zMzORmZnptk8IgTfeeAMrV67EzJkzAQBbt25FTEwMtm/fjt/+9reoqqrCpk2b8N577+Hhhx8GALz//vuIjY3F4cOHMWnSJInVISLqWl49J1paWgqbzYaMjAx1msFgQEpKCk6cOAEAOH36NBobG13GWCwWJCQkqGPu5HA4YLfbXRoRUXfg1RC12WwAgJiYGJfpMTExap/NZkNQUBAiIiJaHXOnnJwcGI1GtcXGxnqzbCKiTtPk03lFUVxeCyFaTLtTW2OysrJQVVWltvLycq/VSkQkw6shajKZAKDFHmVFRYW6d2oymdDQ0IBbt261OuZOBoMB4eHhLo2IqDvwaojGx8fDZDIhPz9fndbQ0IDCwkKMHz8eAJCcnAy9Xu8yxmq1ori4WB1DROQvPP50vqamBpcuXVJfl5aW4ty5c4iMjMTAgQOxdOlSrF69GkOGDMGQIUOwevVq9OrVC08++SQAwGg0YsGCBVi+fDn69u2LyMhIrFixAiNHjlQ/rSci8hceh+ipU6eQlpamvl62bBkAYN68ediyZQuee+451NXV4Xe/+x1u3bqFMWPG4NChQwgLC1Pf8/rrryMwMBCzZs1CXV0dHnroIWzZsgU6HZ99RET+xeMQTU1NhRCt32pfURRkZ2cjOzu71THBwcHYsGEDNmzY4OniiYi6FX53nohIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISAJDlIhIAkOUiEgCQ5SISILHIXrs2DFMnz4dFosFiqJgz549al9jYyOef/55jBw5EqGhobBYLHj66afx3XffucwjNTUViqK4tDlz5kivDBFRV/M4RGtra5GYmIiNGze26Lt9+zbOnDmDl156CWfOnMGuXbvwj3/8AzNmzGgxduHChbBarWp75513OrcGREQ+FOjpGzIzM5GZmem2z2g0Ij8/32Xahg0b8MADD6CsrAwDBw5Up/fq1Qsmk8nTxRMRdSuanxOtqqqCoijo06ePy/Tc3FxERUVhxIgRWLFiBaqrq1udh8PhgN1ud2lERN2Bx3uinqivr8cLL7yAJ598EuHh4er0p556CvHx8TCZTCguLkZWVhbOnz/fYi/2Rzk5OXjllVe0LJWIqFM0C9HGxkbMmTMHTqcTb775pkvfwoUL1b8nJCRgyJAhGDVqFM6cOYOkpKQW88rKysKyZcvU13a7HbGxsVqVTkTUYZqEaGNjI2bNmoXS0lIcOXLEZS/UnaSkJOj1epSUlLgNUYPBAIPBoEWpRERSvB6iPwZoSUkJjh49ir59+7b7ngsXLqCxsRFms9nb5RARacrjEK2pqcGlS5fU16WlpTh37hwiIyNhsVjwr//6rzhz5gz27duH5uZm2Gw2AEBkZCSCgoJw+fJl5ObmYsqUKYiKisJXX32F5cuX4/7778eECRO8t2ZERF3A4xA9deoU0tLS1Nc/nqucN28esrOzsXfvXgDAfffd5/K+o0ePIjU1FUFBQfj000+xfv161NTUIDY2FlOnTsWqVaug0+kkVoWIqOt5HKKpqakQQrTa31YfAMTGxqKwsNDTxRIRdUv87jwRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEhigRkQSGKBGRBIYoEZEEj0P02LFjmD59OiwWCxRFwZ49e1z658+fD0VRXNrYsWNdxjgcDixZsgRRUVEIDQ3FjBkzcPXqVakVISLyBY9DtLa2FomJidi4cWOrYyZPngyr1aq2AwcOuPQvXboUu3fvRl5eHo4fP46amhpMmzYNzc3Nnq8BEZEPBXr6hszMTGRmZrY5xmAwwGQyue2rqqrCpk2b8N577+Hhhx8GALz//vuIjY3F4cOHMWnSJE9LIiLyGU3OiRYUFCA6OhpDhw7FwoULUVFRofadPn0ajY2NyMjIUKdZLBYkJCTgxIkTbufncDhgt9tdGhFRd+D1EM3MzERubi6OHDmCtWvX4uTJk0hPT4fD4QAA2Gw2BAUFISIiwuV9MTExsNlsbueZk5MDo9GottjYWG+XTUTUKR4fzrdn9uzZ6t8TEhIwatQoxMXFYf/+/Zg5c2ar7xNCQFEUt31ZWVlYtmyZ+tputzNIiahb0PwSJ7PZjLi4OJSUlAAATCYTGhoacOvWLZdxFRUViImJcTsPg8GA8PBwl0ZE1B1oHqI3b95EeXk5zGYzACA5ORl6vR75+fnqGKvViuLiYowfP17rcoiIvMrjw/mamhpcunRJfV1aWopz584hMjISkZGRyM7OxuOPPw6z2YwrV67gxRdfRFRUFB577DEAgNFoxIIFC7B8+XL07dsXkZGRWLFiBUaOHKl+Wk9E5C88DtFTp04hLS1Nff3jucp58+bhrbfeQlFREbZt24bKykqYzWakpaVh586dCAsLU9/z+uuvIzAwELNmzUJdXR0eeughbNmyBTqdzgurRETUdTwO0dTUVAghWu0/ePBgu/MIDg7Ghg0bsGHDBk8XT0TUrfC780REEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBIYokREEhiiREQSGKJERBI8DtFjx45h+vTpsFgsUBQFe/bscelXFMVt+9Of/qSOSU1NbdE/Z84c6ZUhIupqHodobW0tEhMTsXHjRrf9VqvVpf31r3+Foih4/PHHXcYtXLjQZdw777zTuTUgIvKhQE/fkJmZiczMzFb7TSaTy+u//e1vSEtLwz333OMyvVevXi3GEhH5G03PiV6/fh379+/HggULWvTl5uYiKioKI0aMwIoVK1BdXd3qfBwOB+x2u0sjIuoOPN4T9cTWrVsRFhaGmTNnukx/6qmnEB8fD5PJhOLiYmRlZeH8+fPIz893O5+cnBy88sorWpZKRNQpmoboX//6Vzz11FMIDg52mb5w4UL17wkJCRgyZAhGjRqFM2fOICkpqcV8srKysGzZMvW13W5HbGysdoUTEXWQZiH62Wef4euvv8bOnTvbHZuUlAS9Xo+SkhK3IWowGGAwGLQok4hIimbnRDdt2oTk5GQkJia2O/bChQtobGyE2WzWqhwiIk14vCdaU1ODS5cuqa9LS0tx7tw5REZGYuDAgQD+ebj9wQcfYO3atS3ef/nyZeTm5mLKlCmIiorCV199heXLl+P+++/HhAkTJFaFiKjreRyip06dQlpamvr6x3OV8+bNw5YtWwAAeXl5EEJg7ty5Ld4fFBSETz/9FOvXr0dNTQ1iY2MxdepUrFq1CjqdrpOrQUTkGx6HaGpqKoQQbY555pln8Mwzz7jti42NRWFhoaeLJSLqlvjdeSIiCQxRIiIJDFEiIgkMUSIiCQxRIiIJDFEiIgkMUSIiCQxRIiIJDFEiIgkMUSIiCQxRIiIJDFEiIgkMUSIiCQxRIiIJDFEiIgmaPqhOa3WKE0Jxdnh8fYCAULSpJQBApMGAAEWjBdxJCNxqbESjs+PrT9QTKU4nghwOBHn4u9lcX9+hcX4dol/0roM+pO0bRP9Uo64OtwM6Pt4TEQYDXktKQlQXPVCvyenEy+fPo7iqqkuWR+SvguvqMOLUKYTq9R69r7axsUPj/DpEHQECzR6EYqMiIKBNiAYA6BsUhOg7Hg+tlQanE/oAno0has+Pe6IGD4/ampqaOjSOv4VERBIYokREEhiiREQSGKJERBL8+oOl7sQJoLKxscs+7GkUAk3tPLqaiLTHEPWSWw0NeO7MGei66jpRADccji5bFhG5xxD1EqcQuN7Bi3OJ6O7Bc6JERBK4J0pEd7XKxkZ8WFYGg4efVziamzs0zq9DVAgBwQ9XiKgNNx0OvF1Sotn8/TpE/9/mvyEgUNfh8c6mZtTfsmtYERH1NH4dot+f/srXJRBRD8cPloiIJDBEiYgkMESJiCR4FKI5OTkYPXo0wsLCEB0djUcffRRff/21yxghBLKzs2GxWBASEoLU1FRcuHDBZYzD4cCSJUsQFRWF0NBQzJgxA1evXpVfGyKiriY8MGnSJLF582ZRXFwszp07J6ZOnSoGDhwoampq1DFr1qwRYWFh4qOPPhJFRUVi9uzZwmw2C7vdro5ZtGiR6N+/v8jPzxdnzpwRaWlpIjExUTQ1NXWojqqqKgGAjY2NTfNWVVXVZh55FKJ3qqioEABEYWGhEEIIp9MpTCaTWLNmjTqmvr5eGI1G8fbbbwshhKisrBR6vV7k5eWpY65duyYCAgLEJ5980qHlMkTZ2Ni6qrUXolLnRKv+9/k+kZGRAIDS0lLYbDZkZGSoYwwGA1JSUnDixAkAwOnTp9HY2OgyxmKxICEhQR1zJ4fDAbvd7tKIiLqDToeoEALLli3DL37xCyQkJAAAbDYbACAmJsZlbExMjNpns9kQFBSEiIiIVsfcKScnB0ajUW2xsbGdLZuIyKs6HaKLFy/Gl19+iR07drToU+64HZwQosW0O7U1JisrC1VVVWorLy/vbNlERF7VqRBdsmQJ9u7di6NHj2LAgAHqdJPJBAAt9igrKirUvVOTyYSGhgbcunWr1TF3MhgMCA8Pd2lERN2BRyEqhMDixYuxa9cuHDlyBPHx8S798fHxMJlMyM/PV6c1NDSgsLAQ48ePBwAkJydDr9e7jLFarSguLlbHEBH5DU8+jf/3f/93YTQaRUFBgbBarWq7ffu2OmbNmjXCaDSKXbt2iaKiIjF37ly3lzgNGDBAHD58WJw5c0akp6fzEic2NrZu2bx6iVNrC9m8ebM6xul0ilWrVgmTySQMBoOYOHGiKCoqcplPXV2dWLx4sYiMjBQhISFi2rRpoqysrMN1METZ2Ni6qrUXosr/hqNfsdvtMBqNvi6DiHqAqqqqNj+H4XfniYgkMESJiCQwRImIJDBEiYgkMESJiCQwRImIJDBEiYgkMESJiCT4ZYj64fcDiMhPtZc3fhmi1dXVvi6BiHqI9vLGL7/26XQ68fXXX2P48OEoLy/nrfE0YLfbERsby+2rEW5fbXlj+wohUF1dDYvFgoCA1vc3AztbpC8FBASgf//+AMD7i2qM21db3L7akt2+HblHh18ezhMRdRcMUSIiCX4bogaDAatWrYLBYPB1KXclbl9tcftqqyu3r19+sERE1F347Z4oEVF3wBAlIpLAECUiksAQJSKSwBAlIpLgtyH65ptvIj4+HsHBwUhOTsZnn33m65L8TnZ2NhRFcWkmk0ntF0IgOzsbFosFISEhSE1NxYULF3xYcfd27NgxTJ8+HRaLBYqiYM+ePS79HdmeDocDS5YsQVRUFEJDQzFjxgxcvXq1C9ei+2pv+86fP7/Fz/PYsWNdxmixff0yRHfu3ImlS5di5cqVOHv2LB588EFkZmairKzM16X5nREjRsBqtaqtqKhI7Xvttdewbt06bNy4ESdPnoTJZMIjjzzCG8C0ora2FomJidi4caPb/o5sz6VLl2L37t3Iy8vD8ePHUVNTg2nTpqG5ubmrVqPbam/7AsDkyZNdfp4PHDjg0q/J9m3zqfTd1AMPPCAWLVrkMu3nP/+5eOGFF3xUkX9atWqVSExMdNvndDqFyWQSa9asUafV19cLo9Eo3n777S6q0H8BELt371Zfd2R7VlZWCr1eL/Ly8tQx165dEwEBAeKTTz7pstr9wZ3bVwgh5s2bJ375y1+2+h6ttq/f7Yk2NDTg9OnTyMjIcJmekZGBEydO+Kgq/1VSUgKLxYL4+HjMmTMH33zzDQCgtLQUNpvNZTsbDAakpKRwO3dCR7bn6dOn0djY6DLGYrEgISGB27yDCgoKEB0djaFDh2LhwoWoqKhQ+7Tavn4Xojdu3EBzczNiYmJcpsfExMBms/moKv80ZswYbNu2DQcPHsRf/vIX2Gw2jB8/Hjdv3lS3Jbezd3Rke9psNgQFBSEiIqLVMdS6zMxM5Obm4siRI1i7di1OnjyJ9PR0OBwOANptX7+8FR4AKIri8loI0WIatS0zM1P9+8iRIzFu3DgMHjwYW7duVU/Iczt7V2e2J7d5x8yePVv9e0JCAkaNGoW4uDjs378fM2fObPV9stvX7/ZEo6KioNPpWvzPUVFR0eJ/efJMaGgoRo4ciZKSEvVTem5n7+jI9jSZTGhoaMCtW7daHUMdZzabERcXh5KSEgDabV+/C9GgoCAkJycjPz/fZXp+fj7Gjx/vo6ruDg6HAxcvXoTZbEZ8fDxMJpPLdm5oaEBhYSG3cyd0ZHsmJydDr9e7jLFarSguLuY274SbN2+ivLwcZrMZgIbbt9MfSflQXl6e0Ov1YtOmTeKrr74SS5cuFaGhoeLKlSu+Ls2vLF++XBQUFIhvvvlGfPHFF2LatGkiLCxM3Y5r1qwRRqNR7Nq1SxQVFYm5c+cKs9ks7Ha7jyvvnqqrq8XZs2fF2bNnBQCxbt06cfbsWfHtt98KITq2PRctWiQGDBggDh8+LM6cOSPS09NFYmKiaGpq8tVqdRttbd/q6mqxfPlyceLECVFaWiqOHj0qxo0bJ/r376/59vXLEBVCiD//+c8iLi5OBAUFiaSkJFFYWOjrkvzO7NmzhdlsFnq9XlgsFjFz5kxx4cIFtd/pdIpVq1YJk8kkDAaDmDhxoigqKvJhxd3b0aNHBYAWbd68eUKIjm3Puro6sXjxYhEZGSlCQkLEtGnTRFlZmQ/Wpvtpa/vevn1bZGRkiH79+gm9Xi8GDhwo5s2b12LbabF9eT9RIiIJfndOlIioO2GIEhFJYIgSEUlgiBIRSWCIEhFJYIgSEUlgiBIRSWCIEhFJYIgSEUlgiBIRSWCIEhFJ+P+/dAwrU3OYwQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# review Atari image, and actual observation of the Agent after processing\n",
    "for _ in range(50):\n",
    "    obs, _, _, _ = env.step(env.action_space.sample())\n",
    "\n",
    "obs = np.array(obs)\n",
    "plt.title(\"Game image\")\n",
    "plt.imshow(env.render(\"rgb_array\"))\n",
    "plt.show()\n",
    "plt.title(\"Agent observation (4 frames left to right)\")\n",
    "plt.imshow(obs.transpose([0,2,1]).reshape([state_dim[0],-1]), cmap='Greys_r');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c83a7ff-bbac-4401-9d66-c5f54547bb62",
   "metadata": {
    "id": "3c83a7ff-bbac-4401-9d66-c5f54547bb62"
   },
   "source": [
    "# DEEP Q-NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e60998c2-37f8-4be6-b531-0d454f381b31",
   "metadata": {
    "id": "e60998c2-37f8-4be6-b531-0d454f381b31"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom keras.layers import Conv2D, Dense, Flatten\\n\\ndef create_qmodel(state_shape, n_actions):\\n    network = keras.models.Sequential()\\n\\n    # Keras ignores the first dimension in the input_shape, which is the batch size.\\n    # So just use state_shape for the input shape\\n    network.add(Conv2D(32, (8, 8), strides=4, activation='relu', input_shape=state_shape))\\n    network.add(Conv2D(64, (4, 4), strides=2, activation='relu'))\\n    network.add(Conv2D(64, (3, 3), strides=1, activation='relu'))\\n    network.add(Flatten())\\n    network.add(Dense(512, activation='relu'))\\n    network.add(Dense(n_actions, activation='linear'))\\n\\n    return network\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#V1\n",
    "'''\n",
    "from keras.layers import Conv2D, Dense, Flatten\n",
    "\n",
    "def create_qmodel(state_shape, n_actions):\n",
    "    network = keras.models.Sequential()\n",
    "\n",
    "    # Keras ignores the first dimension in the input_shape, which is the batch size.\n",
    "    # So just use state_shape for the input shape\n",
    "    network.add(Conv2D(32, (8, 8), strides=4, activation='relu', input_shape=state_shape))\n",
    "    network.add(Conv2D(64, (4, 4), strides=2, activation='relu'))\n",
    "    network.add(Conv2D(64, (3, 3), strides=1, activation='relu'))\n",
    "    network.add(Flatten())\n",
    "    network.add(Dense(512, activation='relu'))\n",
    "    network.add(Dense(n_actions, activation='linear'))\n",
    "\n",
    "    return network\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fd2960e2-7999-4c84-9b73-e31fd5b6f609",
   "metadata": {
    "id": "fd2960e2-7999-4c84-9b73-e31fd5b6f609"
   },
   "outputs": [],
   "source": [
    "#V2\n",
    "from keras.layers import Conv2D, Dense, Flatten\n",
    "\n",
    "def create_qmodel(state_shape, n_actions):\n",
    "    network = keras.models.Sequential()\n",
    "    # Keras ignores the first dimension in the input_shape, which is the batch size.\n",
    "    # So just use state_shape for the input shape\n",
    "    network.add(Conv2D(32, (8, 8), strides=4, activation='relu',use_bias=False, input_shape=state_shape,kernel_initializer=tf.compat.v1.variance_scaling_initializer(scale=2)))\n",
    "    network.add(Conv2D(64, (4, 4), strides=2, activation='relu',use_bias=False,kernel_initializer=tf.compat.v1.variance_scaling_initializer(scale=2)))\n",
    "    network.add(Conv2D(64, (3, 3), strides=1, activation='relu',use_bias=False,kernel_initializer=tf.compat.v1.variance_scaling_initializer(scale=2)))\n",
    "    network.add(Conv2D(1024, (7, 7), strides=1, activation='relu',use_bias=False,kernel_initializer=tf.compat.v1.variance_scaling_initializer(scale=2)))\n",
    "    network.add(Flatten())\n",
    "    network.add(Dense(n_actions, activation='linear',kernel_initializer=tf.compat.v1.variance_scaling_initializer(scale=2)))\n",
    "\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5613ae5-ce29-42e5-8fc4-72bb2a2a82c8",
   "metadata": {
    "id": "e5613ae5-ce29-42e5-8fc4-72bb2a2a82c8"
   },
   "source": [
    "# REPLAY MEMORY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d8ed90c-396e-4fdf-905d-6462eadd2e8d",
   "metadata": {
    "id": "3d8ed90c-396e-4fdf-905d-6462eadd2e8d"
   },
   "outputs": [],
   "source": [
    "# This code is shamelessly stolen from https://github.com/openai/baselines/blob/master/baselines/deepq/replay_buffer.py\n",
    "import random\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "    def __init__(self, size):\n",
    "        \"\"\"Create Replay buffer.\n",
    "        Parameters\n",
    "        ----------\n",
    "        size: int\n",
    "            Max number of transitions to store in the buffer. When the buffer\n",
    "            overflows the old memories are dropped.\n",
    "        \"\"\"\n",
    "        self._storage = []\n",
    "        self._maxsize = size\n",
    "        self._next_idx = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._storage)\n",
    "\n",
    "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
    "        data = (obs_t, action, reward, obs_tp1, done)\n",
    "\n",
    "        if self._next_idx >= len(self._storage):\n",
    "            self._storage.append(data)\n",
    "        else:\n",
    "            self._storage[self._next_idx] = data\n",
    "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
    "\n",
    "    def _encode_sample(self, idxes):\n",
    "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
    "        for i in idxes:\n",
    "            data = self._storage[i]\n",
    "            obs_t, action, reward, obs_tp1, done = data\n",
    "            obses_t.append(np.array(obs_t, copy=False))\n",
    "            actions.append(np.array(action, copy=False))\n",
    "            rewards.append(reward)\n",
    "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
    "            dones.append(done)\n",
    "        return np.array(obses_t), np.array(actions), np.array(rewards), np.array(obses_tp1), np.array(dones)\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Sample a batch of experiences.\n",
    "        Parameters\n",
    "        ----------\n",
    "        batch_size: int\n",
    "            How many transitions to sample.\n",
    "        Returns\n",
    "        -------\n",
    "        obs_batch: np.array\n",
    "            batch of observations\n",
    "        act_batch: np.array\n",
    "            batch of actions executed given obs_batch\n",
    "        rew_batch: np.array\n",
    "            rewards received as results of executing act_batch\n",
    "        next_obs_batch: np.array\n",
    "            next set of observations seen after executing act_batch\n",
    "        done_mask: np.array\n",
    "            done_mask[i] = 1 if executing act_batch[i] resulted in\n",
    "            the end of an episode and 0 otherwise.\n",
    "        \"\"\"\n",
    "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
    "        return self._encode_sample(idxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3ef52c-cc4e-43e2-8512-82ee5f43af99",
   "metadata": {
    "id": "7c3ef52c-cc4e-43e2-8512-82ee5f43af99"
   },
   "source": [
    "# EPSILON GREEDY STRATEGY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5533c11-5069-4771-8af6-6e9869970744",
   "metadata": {
    "id": "e5533c11-5069-4771-8af6-6e9869970744"
   },
   "outputs": [],
   "source": [
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self, current, max, min, epsilon_random_frames, epsilon_greedy_frames):\n",
    "        self.current = current\n",
    "        self.max = max\n",
    "        self.min = min\n",
    "        self.epsilon_random_frames = epsilon_random_frames\n",
    "        self.epsilon_greedy_frames = epsilon_greedy_frames\n",
    "\n",
    "    def decay_epsilon(self):\n",
    "        # Decay probability of taking random action\n",
    "        self.current -= (self.max - self.min)/self.epsilon_greedy_frames\n",
    "        return self.current"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c91de8-09d6-4735-99cd-1746c15df476",
   "metadata": {
    "id": "d4c91de8-09d6-4735-99cd-1746c15df476"
   },
   "source": [
    "# AGENT CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbe0814d-f120-4d36-9a1c-835f3abae2a5",
   "metadata": {
    "id": "cbe0814d-f120-4d36-9a1c-835f3abae2a5"
   },
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self, strategy, num_actions):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "\n",
    "    def select_action(self, state, policy_net):\n",
    "        action = 0\n",
    "        epsilon = self.strategy.current\n",
    "\n",
    "        if epsilon > random.random() or self.current_step < self.strategy.epsilon_random_frames:\n",
    "            action = random.randrange(self.num_actions) #explore\n",
    "        else:\n",
    "            action_probs = policy_net(state, training=False)\n",
    "            # Take best action\n",
    "            act = tf.argmax(action_probs[0]).numpy() #exploit\n",
    "            #print(action)\n",
    "            action = act\n",
    "\n",
    "        epsilon = self.strategy.decay_epsilon()\n",
    "        self.strategy.current = max(epsilon, self.strategy.min)\n",
    "        self.current_step += 1\n",
    "\n",
    "        return action        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "769f353c-b25e-4ba0-b60a-66c90371519c",
   "metadata": {
    "id": "769f353c-b25e-4ba0-b60a-66c90371519c",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def save_agent(agent, save_path, save_name):\n",
    "    # Create folder if it does not exists\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    # Save the entire object to a file using pickle\n",
    "    with open(os.path.join(save_path, save_name) + '.pkl', 'wb') as file:\n",
    "        pickler = pickle.Pickler(file)\n",
    "        pickler.dump(agent)\n",
    "\n",
    "def load_agent(load_path, load_name):\n",
    "    # Load the entire object from the file using pickle\n",
    "    with open(os.path.join(load_path, load_name) + '.pkl', 'rb') as file:\n",
    "        loaded_agent = pickle.load(file)\n",
    "\n",
    "    return loaded_agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b10ebab-6bea-41b3-95a1-d7a9a7d2fc5a",
   "metadata": {
    "id": "6b10ebab-6bea-41b3-95a1-d7a9a7d2fc5a"
   },
   "source": [
    "# HYPER-PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c443e058-4369-4c92-9d75-0f6a339b3084",
   "metadata": {
    "id": "c443e058-4369-4c92-9d75-0f6a339b3084",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "epsilon = 1.0  # Epsilon greedy parameter\n",
    "epsilon_min = 0.1  # Minimum epsilon greedy parameter\n",
    "epsilon_max = 1.0  # Maximum epsilon greedy parameter\n",
    "# Number of frames to take random action and observe output\n",
    "epsilon_random_frames = 50000\n",
    "# Number of frames for exploration\n",
    "epsilon_greedy_frames = 1000000.0\n",
    "update_after_actions = 4\n",
    "#num_episodes = 1000\n",
    "max_steps_per_episode = 10000\n",
    "update_target_network = 10000\n",
    "batch_size = 64\n",
    "gamma = 0.99\n",
    "max_memory_length = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2328a906-4e4e-457b-814b-cb2db2f5889a",
   "metadata": {
    "id": "2328a906-4e4e-457b-814b-cb2db2f5889a"
   },
   "outputs": [],
   "source": [
    "policy_net = create_qmodel(state_dim, n_actions)\n",
    "target_net = create_qmodel(state_dim, n_actions)\n",
    "optimizer = keras.optimizers.Adam(learning_rate=0.00025, clipnorm=1.0)\n",
    "loss_function = keras.losses.Huber()\n",
    "strategy = EpsilonGreedyStrategy(current = epsilon,\n",
    "                                     max = epsilon_max,\n",
    "                                     min = epsilon_min,\n",
    "                                     epsilon_random_frames = epsilon_random_frames,\n",
    "                                     epsilon_greedy_frames = epsilon_greedy_frames)\n",
    "\n",
    "agent = Agent(strategy, n_actions)\n",
    "#ho commentato altrimenti ho problemi di RAM sul mio pc, non su colab \n",
    "#memory = ReplayBuffer(max_memory_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "803684eb-96aa-40d9-b095-5f39fdba8c48",
   "metadata": {
    "id": "803684eb-96aa-40d9-b095-5f39fdba8c48"
   },
   "outputs": [],
   "source": [
    "#checkpoints modello e optimizer, per eseguire run successive\n",
    "ckpt = tf.train.Checkpoint(model=policy_net, optimizer=optimizer)\n",
    "manager = tf.train.CheckpointManager(ckpt, './v2/tf_ckpts', max_to_keep=3)\n",
    "\n",
    "agent_dir = './v2/agent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9eac70a0-fbfe-4fc3-b765-5d84fd5f25ca",
   "metadata": {
    "id": "9eac70a0-fbfe-4fc3-b765-5d84fd5f25ca"
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "def play_and_record(agent, policy_net, env, n_steps=1):\n",
    "    \"\"\"\n",
    "    Play the game for exactly n steps, record every (s,a,r,s', done) to replay buffer.\n",
    "    Whenever game ends, add record with done=True and reset the game.\n",
    "    \"\"\"\n",
    "    # State at the beginning of rollout\n",
    "    s = np.array(env.reset())\n",
    "\n",
    "    # Play the game for n_steps as per instructions above\n",
    "    for t in trange(n_steps):\n",
    "        # get agent to pick action given state s\n",
    "        state_tensor = tf.convert_to_tensor(s)\n",
    "        state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "        #seleziona azione tramite strategia epsilon-greedy\n",
    "        action = agent.select_action(state_tensor, policy_net)\n",
    "        #print(action)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        next_state = np.array(next_state)\n",
    "\n",
    "        # add to replay buffer\n",
    "        memory.add(s, action, reward, next_state, done)\n",
    "        if done:\n",
    "            s = np.array(env.reset())\n",
    "        else:\n",
    "            s = next_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "eb931888-dd43-4c4a-b927-2dbd89ea8f0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eb931888-dd43-4c4a-b927-2dbd89ea8f0e",
    "outputId": "156cf3ea-dd3d-4ebd-811c-e9434fb557a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filling replay memory...\n"
     ]
    }
   ],
   "source": [
    "print('Filling replay memory...')\n",
    "#uncomment to fill replay memory\n",
    "#play_and_record(agent, policy_net, env, n_steps=20000)\n",
    "#len(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dc4e1ca-184b-429e-b4ff-6c775b96c801",
   "metadata": {
    "id": "4dc4e1ca-184b-429e-b4ff-6c775b96c801"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom datetime import datetime\\n\\ncurrent_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\\nlog_dir = f\\'./v2/logs/{current_time}\\'\\n# Callback per TensorBoard\\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\\n\\n%load_ext tensorboard\\n%tensorboard --logdir ./v2/logs\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from datetime import datetime\n",
    "\n",
    "current_time = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = f'./v2/logs/{current_time}'\n",
    "# Callback per TensorBoard\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1, write_graph=True, write_images=True)\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./v2/logs\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79fdfde-56d4-4cb2-a047-7e1ea47b7d5d",
   "metadata": {
    "id": "a79fdfde-56d4-4cb2-a047-7e1ea47b7d5d"
   },
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23057f9e-4d0c-4f6e-8f68-f15790cbb2f8",
   "metadata": {
    "id": "23057f9e-4d0c-4f6e-8f68-f15790cbb2f8"
   },
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from IPython.display import clear_output\n",
    "from pandas import DataFrame\n",
    "moving_average = lambda x, span, **kw: DataFrame({'x':np.asarray(x)}).x.ewm(span=span, **kw).mean().values\n",
    "%matplotlib inline\n",
    "\n",
    "def train(env, agent, policy_net, target_net, memory, loss_function, optimizer, log_dir, agent_dir, ckpt, manager, resume = False):\n",
    "    running_reward = 0\n",
    "    frame_count = 0\n",
    "    episode_count = 0\n",
    "    episode_rw_history = []\n",
    "    td_loss_history = []\n",
    "    epsilon_history = []\n",
    "\n",
    "    if(resume):\n",
    "        ckpt.restore(manager.latest_checkpoint)\n",
    "        if manager.latest_checkpoint:\n",
    "            print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "            agent = load_agent(agent_dir, 'agent')\n",
    "        else:\n",
    "            print(\"Initializing from scratch.\")\n",
    "\n",
    "\n",
    "    while True:\n",
    "        state = np.array(env.reset())\n",
    "        episode_rw = 0\n",
    "        for timestep in range(1, max_steps_per_episode):\n",
    "            #Adding this line would show the attempts\n",
    "            #env.render();\n",
    "            # Print the result\n",
    "            frame_count += 1\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "\n",
    "            #seleziona azione tramite strategia epsilon-greedy\n",
    "            action = agent.select_action(state_tensor, policy_net)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = np.array(next_state)\n",
    "            episode_rw += reward\n",
    "             # Save actions and states in replay buffer\n",
    "            memory.add(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "\n",
    "            if frame_count % update_after_actions == 0 and len(memory) > batch_size:\n",
    "                # Get samples from replay buffer\n",
    "                state_sample, action_sample, rewards_sample, next_state_sample, done_sample = memory.sample(batch_size)\n",
    "\n",
    "                next_qvalues =  target_net.predict(next_state_sample, verbose=0)\n",
    "                max_next_qvalues = tf.reduce_max(next_qvalues, axis=1)\n",
    "\n",
    "                #lato destro equazione bellman ford\n",
    "                target_qvalues = rewards_sample + gamma * max_next_qvalues\n",
    "                # If final frame set the last value to -1\n",
    "                target_qvalues = target_qvalues * (1 - done_sample) - done_sample\n",
    "\n",
    "                with tf.GradientTape() as tape:\n",
    "                    current_qvalues = policy_net(state_sample)\n",
    "                    #q-values relativi alle azioni nelle esperienze campionate\n",
    "                    current_action_qvalues = tf.reduce_sum(tf.one_hot(tf.cast(action_sample, dtype=tf.int32), n_actions) * current_qvalues, axis=1)\n",
    "                    td_loss = loss_function(target_qvalues, current_action_qvalues)\n",
    "                 # Backpropagation\n",
    "                grads = tape.gradient(td_loss, policy_net.trainable_variables)\n",
    "                optimizer.apply_gradients(zip(grads, policy_net.trainable_variables))\n",
    "                td_loss_history.append(td_loss)\n",
    "            #target network update\n",
    "            if frame_count % update_target_network == 0:\n",
    "                target_net.set_weights(policy_net.get_weights())\n",
    "                # Log details\n",
    "                template = \"running reward: {:.2f} at episode {}, frame count {}, epsilon {:.5f}\"\n",
    "                print(template.format(running_reward, episode_count, frame_count, agent.strategy.current))\n",
    "\n",
    "                with tf.summary.create_file_writer(log_dir).as_default():\n",
    "                  tf.summary.scalar('running Reward', running_reward, step = agent.current_step)\n",
    "                  tf.summary.scalar('Td loss', np.mean(td_loss_history), step = agent.current_step)\n",
    "                  tf.summary.scalar('Epsilon',agent.strategy.current , step = agent.current_step)\n",
    "\n",
    "\n",
    "            if frame_count % 100000 == 0:\n",
    "                save_path = manager.save()\n",
    "                print(\"Saved checkpoint for step {}: {}\".format(frame_count, save_path))\n",
    "                save_agent(agent, agent_dir, 'agent')\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "\n",
    "        episode_rw_history.append(episode_rw)\n",
    "        # Update running reward to check condition for solving\n",
    "        if len(episode_rw_history) > 100:\n",
    "            del episode_rw_history[:1]\n",
    "        running_reward = np.mean(episode_rw_history)\n",
    "\n",
    "        episode_count += 1\n",
    "\n",
    "        if running_reward > 40:  # Condition to consider the task solved\n",
    "            print(\"Solved at episode {}!\".format(episode_count))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "vk_QBK4WzTYp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 354
    },
    "id": "vk_QBK4WzTYp",
    "outputId": "1b57dd1f-9d72-42e9-a58a-b62190935f63"
   },
   "outputs": [],
   "source": [
    "#train(env,agent, policy_net, target_net, memory, loss_function, optimizer, log_dir, agent_dir, ckpt, manager, resume = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a75ad1-18ce-452a-930b-11ea28e21ebe",
   "metadata": {},
   "source": [
    "Sull'asse X il numero di step e sull'asse Y la running reward (media delle reward cumulate degli ultimi 100 episodi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef56559-ca64-466e-9db1-ed43558bcfc8",
   "metadata": {},
   "source": [
    "### Running Reward training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624f6d5-9376-4ba5-bece-ee57eda53b0e",
   "metadata": {
    "id": "d856afae-e1ed-4691-80da-170b8f47edb8"
   },
   "source": [
    "![POLICY_NETWORK](images/runningRewardV2.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44dbe70-b985-4e22-ae28-8274fbe47412",
   "metadata": {},
   "source": [
    "In fase di valutazione il modello è stato valutato con epsilon pari a 0 (ossia scegliendo sempre l'azione con q-value maggiore), il miglior punteggio ottenuto è 358"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d23b91f5-ec3c-41dc-9077-d7eb14cd0af9",
   "metadata": {
    "id": "d23b91f5-ec3c-41dc-9077-d7eb14cd0af9"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import trange\n",
    "\n",
    "#Evaluate agents performance, in a number of games\n",
    "def evaluate(env, policy_net, n_games=1,t_max=1000):\n",
    "    \"\"\" Plays n_games. Returns mean reward. \"\"\"\n",
    "    rewards = []\n",
    "    #state = np.array(env.reset())\n",
    "    for _ in trange(n_games):\n",
    "        r = 0\n",
    "        state = env.reset()\n",
    "        for _ in range(t_max):\n",
    "            env.render()\n",
    "            time.sleep(.1)\n",
    "            state_tensor = tf.convert_to_tensor(state)\n",
    "            state_tensor = tf.expand_dims(state_tensor, 0)\n",
    "            action_q = policy_net(state_tensor, training=False)\n",
    "            # Take best action\n",
    "            action = tf.argmax(action_q[0]).numpy() #exploit\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = np.array(next_state)\n",
    "            r += reward\n",
    "\n",
    "            if done:\n",
    "              #state = env.reset()\n",
    "              break\n",
    "\n",
    "            else:\n",
    "                state = next_state\n",
    "\n",
    "        rewards.append(r)\n",
    "\n",
    "    env.close()\n",
    "    return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2c96e73e-a6b2-42ae-afc4-371cfcc7421e",
   "metadata": {
    "id": "2c96e73e-a6b2-42ae-afc4-371cfcc7421e"
   },
   "outputs": [],
   "source": [
    "#agent = load_agent(agent_dir, 'agent')\n",
    "policy_net.load_weights('./trained_model.h5')\n",
    "#ckpt.restore('./v2/tf_ckpts/ckpt-46')\n",
    "#policy_net.save_weights('./weights/v2_best_trained_model.h5', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0cd53-5113-4621-9b47-bd8b37e534f0",
   "metadata": {
    "id": "81f0cd53-5113-4621-9b47-bd8b37e534f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/20 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "results = evaluate(env, policy_net, n_games = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975137fa-7468-4650-9e94-85cc69822123",
   "metadata": {
    "id": "975137fa-7468-4650-9e94-85cc69822123"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28b0028-7ea6-44ce-995b-674232fcab06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
